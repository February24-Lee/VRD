{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominican-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "scientific-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.vgg import vgg16\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from os import listdir\n",
    "import json\n",
    "\n",
    "from src.VRDDataLoader import VRD_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "former-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrd_object_list_path = '../../Share_Data/VRD/objects.json'\n",
    "vrd_anno_json_path = '../../Share_Data/VRD/annotations_train.json'\n",
    "sg_anno_json_path = '../../Share_Data/VRD/sg_dataset/sg_train_annotations.json'\n",
    "img_folder_path = '../../Share_Data/VRD/sg_dataset/sg_train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "equipped-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ds = VRD_Dataset(vrd_object_list_path,\n",
    "                     vrd_anno_json_path,\n",
    "                     sg_anno_json_path,\n",
    "                     img_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "portuguese-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loader = DataLoader(my_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "selective-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = next(iter(ds_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "contemporary-cherry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0.0431, 0.0471, 0.0588,  ..., 0.1059, 0.1098, 0.1176],\n",
       "           [0.0431, 0.0510, 0.0588,  ..., 0.0980, 0.1098, 0.1137],\n",
       "           [0.0431, 0.0510, 0.0588,  ..., 0.0941, 0.0941, 0.1020],\n",
       "           ...,\n",
       "           [0.2196, 0.2314, 0.2510,  ..., 0.1020, 0.0784, 0.0745],\n",
       "           [0.2157, 0.2314, 0.2588,  ..., 0.1020, 0.0902, 0.0784],\n",
       "           [0.2157, 0.2275, 0.2588,  ..., 0.1059, 0.0902, 0.0902]],\n",
       " \n",
       "          [[0.0314, 0.0353, 0.0392,  ..., 0.0902, 0.0941, 0.0941],\n",
       "           [0.0314, 0.0392, 0.0392,  ..., 0.0941, 0.0941, 0.0980],\n",
       "           [0.0314, 0.0392, 0.0392,  ..., 0.0902, 0.0902, 0.0863],\n",
       "           ...,\n",
       "           [0.1098, 0.1020, 0.1098,  ..., 0.0431, 0.0353, 0.0353],\n",
       "           [0.1059, 0.1020, 0.1137,  ..., 0.0431, 0.0392, 0.0392],\n",
       "           [0.1059, 0.0980, 0.1137,  ..., 0.0392, 0.0353, 0.0431]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0157,  ..., 0.0863, 0.0902, 0.0941],\n",
       "           [0.0039, 0.0118, 0.0157,  ..., 0.0863, 0.0902, 0.0941],\n",
       "           [0.0039, 0.0118, 0.0157,  ..., 0.0824, 0.0824, 0.0745],\n",
       "           ...,\n",
       "           [0.0627, 0.0275, 0.0078,  ..., 0.0157, 0.0118, 0.0314],\n",
       "           [0.0588, 0.0275, 0.0118,  ..., 0.0157, 0.0157, 0.0431],\n",
       "           [0.0588, 0.0314, 0.0118,  ..., 0.0118, 0.0235, 0.0510]]]]),\n",
       " tensor([800]),\n",
       " tensor([533]),\n",
       " tensor([[ 5, 22,  7,  7,  7,  7,  7]]),\n",
       " tensor([[[324., 336., 458., 489.],\n",
       "          [306.,  94., 590., 175.],\n",
       "          [539., 265., 680., 397.],\n",
       "          [425., 273., 556., 394.],\n",
       "          [302., 270., 420., 396.],\n",
       "          [159., 272., 293., 401.],\n",
       "          [ 47., 271., 156., 407.]]])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-frontier",
   "metadata": {},
   "source": [
    "### Test img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "scheduled-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img, w, h, test_label, test_bb = my_ds[0]\n",
    "test_img = test_img.unsqueeze(0)\n",
    "\n",
    "test_label = test_label.type(torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-candle",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "understood-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = vgg16().features\n",
    "backbone.out_channels = 512\n",
    "\n",
    "anachor_generator = AnchorGenerator(sizes=((64, 128, 256),),\n",
    "                                    aspect_ratios=((0.5, 1, 2),))\n",
    "\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
    "                                                output_size=7,\n",
    "                                                sampling_ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "suspected-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = FasterRCNN(backbone,\n",
    "                     num_classes=100,\n",
    "                     rpn_anchor_generator=anachor_generator,\n",
    "                     box_roi_pool=roi_pooler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "herbal-martin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(512, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=25088, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=100, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-magazine",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bearing-democracy",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-68ea58474983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "portable-science",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.train()\n",
    "my_model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecological-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = my_model(test_img, \n",
    "                  [{'boxes':test_bb,\n",
    "                   'labels':test_label},])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "liable-lucas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('loss_classifier', tensor(4.6115, grad_fn=<NllLossBackward>)), ('loss_box_reg', tensor(0.1155, grad_fn=<DivBackward0>)), ('loss_objectness', tensor(0.6964, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)), ('loss_rpn_box_reg', tensor(0.0527, grad_fn=<DivBackward0>))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "permanent-donna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.611452579498291"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['loss_classifier'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "endangered-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ordinary-damages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(4.5968, grad_fn=<NllLossBackward>),\n",
       " 'loss_box_reg': tensor(0.1530, grad_fn=<DivBackward0>),\n",
       " 'loss_objectness': tensor(0.6927, grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
       " 'loss_rpn_box_reg': tensor(0.0526, grad_fn=<DivBackward0>),\n",
       " 'loss': tensor(5.4951, grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(**output, **{'loss':loss_sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "burning-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'loss':loss_sum}.update(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "experimental-columbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4951, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "partial-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(4.5968, grad_fn=<NllLossBackward>),\n",
       " 'loss_box_reg': tensor(0.1530, grad_fn=<DivBackward0>),\n",
       " 'loss_objectness': tensor(0.6927, grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
       " 'loss_rpn_box_reg': tensor(0.0526, grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "adequate-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sum = reduce(lambda x, y : x+y, list(output.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "about-bidder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(512, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=25088, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=100, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-elite",
   "metadata": {},
   "source": [
    "### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "royal-navigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "driving-lindsay",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(512, 9, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=25088, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "preceding-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = my_model([test_img,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-young",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VRD",
   "language": "python",
   "name": "vrd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
